# **Neural Network**

## Resume 

Artificial neural networks are an attempt to simulate the learning behavior of the brain. The first experiments involve connecting parts of the brain to stimulate learning

## Table of Contents
1. [Available library](#available-library)
2. [Types of IA tools](#types-of-ia-tools)
3. [Neurons](#neurons)
4. [What is an Activation Function ](#what-is-an-activation-function)
5. [Loses functions](#loses-functions)
6. [Key concepts](#key-concepts)

## Available library

1. [TensorFlow](https://www.tensorflow.org/)
2. [PyTorch](https://pytorch.org/)

## Types of IA tools

Artificial intelligence ⇒ Seeks to replicate human intelligence.

Machine learning ⇒ Techniques that seek to replicate machine learning.

Deep learning ⇒ Deep learning,


## Neurons

![https://images.app.goo.gl/aJ2Jga1WPVdSqxXv7](docs/neurona.png)
> Interconnected nerve cells

The perceptron is an artificial neuron that seeks to imitate the functioning of the brain's neurons. The objective is to have several perceivers in order to communicate with each other. This is done in order to include atypical cases. It is used in supervised learning. , in this way the weights are altered as the results coincide with the real data

![Screenshot 2023-08-18 at 9.03.11 PM.png](docs/Screenshot_2023-08-18_at_9.03.11_PM.png)


$$
\begin{pmatrix}
W_{11} & W_{12} & W_{13} & ... & W_{1n} \\
W_{21} & W_{22} & W_{23} & ... & W_{2n} \\
... & ... & ... &  & ...                \\
W_{m1} & W_{m2} & W_{m3} & ... & W_{mn} 
\end{pmatrix}
*
\begin{pmatrix}
X_{1} \\
X_{2} \\
X_{3} \\
... \\
X_{n}
\end{pmatrix} = \begin{pmatrix}
X_{1} * W_{11} + X_{2} * W_{12} + X_{3} * W_{13} + ... + X_{n} * W_{1n} \\
X_{1} * W_{21} + X_{2} * W_{22} + X_{3} * W_{23} + ... + X_{n} * W_{2n} \\
... \\
X_{1} * W_{m1} + X_{2} * W_{m2} + X_{3} * W_{m3} + ... + X_{n} * W_{mn}
\end{pmatrix}
$$


### What is an Activation Function 

posterior area of a neuron where there is a filter, activation function, which modifies the result value, transmits the information generated by the weights and inputs, this is useful for solving problems with high difficulty.

> What kind of activation function is used

```python
import numpy as np

sigmoid = lambda x : 1 / (1 + np.exp(-x))
step = lambda x: np.piecewise(x, [x < 0, x >= 0], [0, 1])
relu = lambda x : np.piecewise(x, [x < 0, x >= 0], [0, lambda a : a])
```

### Loses functions

They are functions that measure the percentage of error that the network model had, for practical purposes the lowest value is the best

- Learning rate ⇒ It means the pace with which the value will be measured. Consider the following case
     - Very short steps, greater ability to find the minimum error, however it has a high computational cost.
     - Very long steps, lousy performance, may not find the minimum value of the loss function due to its high volatility in the function

Moment ⇒ It is used to calculate the rate or speed of Learning rate in order to find the global minimum.


### Data types 

- Scalar, it has no dimension.
- Vector, one dimension.
- Matrix, two vectors.
- Tensor, greater than 3 dimensions.


### Key Concepts

Time series, 3 dimensions,

1. Number of examples.
2. Characteristics of the examples
3. Change of the example over time.

4 dimensions

Images, rgb, + quantities of examples

## References


